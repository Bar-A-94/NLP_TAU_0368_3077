{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPKTqQ3W8qLt"
      },
      "source": [
        "To begin copy this notebook to your own drive:\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "\n",
        "### Submission Instructions:\n",
        "1. **Restart the kernel** (in the menubar, select Runtime$\\rightarrow$Restart runtime)\n",
        "2. **Run all cells** (in the menubar, select Runtime$\\rightarrow$Run All).\n",
        "3. **Download the notebook** (in the menubar, select File$\\rightarrow$Download .ipynb)\n",
        "4. **Upload the downloaded notebook (.ipynb file) to your repository**.\n",
        "\n",
        "Note: To use a GPU, do the following: Runtime$\\rightarrow$Change runtime type$\\rightarrow$ GPU\n",
        "\n",
        "Make sure you fill in any place that says `YOUR CODE HERE`, and that no tests fail.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "XvPkt7Zm8qLt",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "5493400e8b7f9a8e2cde874866d4fa7f",
          "grade": false,
          "grade_id": "cell-3a1bca1dbb7d0069",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "![shakespeare](https://i.imgur.com/81YZuel.jpg)\n",
        "\n",
        "# Generating Shakespeare Using a Character-level Language Model\n",
        "\n",
        "### From Words to Characters\n",
        "In the previous two sections we dealt with word-level language models. But looking again at section 2, there is nothing that constraints us to using _words_ as the basic elemnents in our model. The model we analyzed in section 2 could just as well be character-based - just replace \"word\" with \"character\", and you are good to go. In this notebook we will train a small character-based language model that will help us generate Shakespearean-like (emphasis on the _like_...) texts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "EvGyr_ux8qLt",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "9af7a343d0e3524c3fd846d987d766a8",
          "grade": false,
          "grade_id": "cell-7301754e4d655d01",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Question 3.a\n",
        "Can you think of an advantage a character-based language model could have over a word-based language model? And what about the other way around: can you think of an advantage a word-based language model could have over a character-based language model? (Add your answer to the final submission pdf)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "ghCevRFf8qLt",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "d46a8dfd340b8f68e51a041307f7d7d3",
          "grade": false,
          "grade_id": "cell-ebc0d8ae3061c0fc",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Using PyTorch\n",
        "\n",
        "We'll build our language model using PyTorch. PyTorch is a [very popular](https://thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry/) open-source machine learning (and deep learning) framework developed by Facebook. In short:\n",
        "\n",
        "> Pytorch is a Python-based scientific computing package targeted at two sets of audiences:\n",
        "* A replacement for NumPy to use the power of GPUs\n",
        "* A deep learning research platform that provides maximum flexibility and speed\n",
        "\n",
        "To get familiar with PyTorch, check out this [quick tutorial](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html). In addition, another imporant difference from numpy is that PyTorch can automatically calculate the gradients needed for backpropagation, as explained [here](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "MYd79g6k8qLt",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "02af8a21a2e8fae58d84f915de5b016d",
          "grade": false,
          "grade_id": "cell-aa2773db1bef7014",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Preparing the Data\n",
        "\n",
        "Our dataset is a plain text file. For simplicity, we turn any potential unicode characters into plain ASCII by using the `unidecode` package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OT5WdSbsFT1K",
        "outputId": "d7b21156-e469-463b-9ba9-b92e4cf6bf24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: unidecode in /opt/anaconda3/lib/python3.12/site-packages (1.3.8)\n"
          ]
        }
      ],
      "source": [
        "!pip install unidecode\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "RYqFoQgV8qLt",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ef0359e8c08b2057771c115150011e7e",
          "grade": false,
          "grade_id": "cell-cce75419c097f3fd",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "2726b5e9-17a7-4c51-f92c-fe6973828619",
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of characters in our dataset: 1115394\n"
          ]
        }
      ],
      "source": [
        "import string\n",
        "import random\n",
        "import re\n",
        "import requests\n",
        "import unidecode\n",
        "url = \"https://github.com/tau-nlp-course/NLP_HW2/raw/main/data/shakespeare.txt\"\n",
        "\n",
        "\n",
        "all_characters = string.printable\n",
        "n_characters = len(all_characters)  # our vocabulary size (|V| from the handout)\n",
        "\n",
        "dataset_as_string = unidecode.unidecode(requests.get(url).content.decode())\n",
        "n_chars_in_dataset = len(dataset_as_string)\n",
        "print(f'Total number of characters in our dataset: {n_chars_in_dataset}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "mIctyT3J8qLu",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "06dd2ac91a6296206475c7e330e53e3d",
          "grade": false,
          "grade_id": "cell-d795f907dd7922f3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "To make inputs out of this big string of text, we will split it into chunks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "eoLs0ivz8qLu",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "61947ad22fb7f16eba246d47ab8cae22",
          "grade": false,
          "grade_id": "cell-379f229536dae19b",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "7e36a18c-ecc8-4c37-db46-07018cb2266a",
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "e,\n",
            "O'erthrows thy joys, friends, fortune and thy state:\n",
            "For all the Welshmen, hearing thou wert dead.\n",
            "Are gone to Bolingbroke, dispersed and fled.\n",
            "\n",
            "DUKE OF AUMERLE:\n",
            "Comfort, my liege; why looks your grace so pale?\n",
            "\n",
            "KING RICHARD II:\n",
            "But now the blood of twenty thousand men\n",
            "Did triumph in my face, and they are fled;\n",
            "And, till so much blood thither come again,\n",
            "Have I not reason to look pale and dead?\n",
            "\n"
          ]
        }
      ],
      "source": [
        "chunk_len = 400\n",
        "\n",
        "def random_chunk():\n",
        "    start_index = random.randint(0, n_chars_in_dataset - chunk_len)\n",
        "    end_index = start_index + chunk_len + 1\n",
        "    return dataset_as_string[start_index:end_index]\n",
        "\n",
        "print(random_chunk())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "ho8WlUcV8qLv",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "ba5d4900ff254fa335fe935962878c8d",
          "grade": false,
          "grade_id": "cell-fcbb2d73f4e442fb",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Building Our Model\n",
        "\n",
        "Our model consists of three main components:\n",
        "\n",
        "1. [**Embedding**](https://pytorch.org/docs/stable/nn.html#embedding). A mapping between characters and their learned representations (\"word vectors\") \\[correspoding to ${\\boldsymbol L}$ in terms of the handout\\]\n",
        "2. [**GRU**](https://pytorch.org/docs/stable/nn.html#gru). \\[correspoding to the computation of ${\\boldsymbol h}^{(t)}$ in terms of the handout\\]\n",
        "3. **Output Layer**. A feed-forward neural network that transforms a hidden state at a timestep into a probability distribution of the next character. \\[correspoding to the computation of $\\hat{\\boldsymbol y}^{(t)}$ in terms of the handout\\]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFm8g2pd8qLv"
      },
      "source": [
        "### Question 3.b\n",
        "Complete the implementation of the `forward` method of our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "deletable": false,
        "id": "2SoCQ_ZM8qLv",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a9ad1239fcd5aec23f439249397895ec",
          "grade": false,
          "grade_id": "cell-1640492438386e87",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class OurModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
        "        super(OurModel, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)  # In the terms of the handout, here d = D_h\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, num_layers)\n",
        "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, input_, hidden):\n",
        "        # General instructions:\n",
        "        # Pass the embedded input through the GRU and use the output layer to get the next character distribution.\n",
        "        # return that distribution and the next hidden state.\n",
        "        # You may need to play around with the dimensions a bit until you get it right. Dimension-induced frustration is good for you!\n",
        "        # -------------------------\n",
        "        # YOUR CODE HERE\n",
        "        # Reshape input to [1, 1] if it's a scalar tensor\n",
        "        if input_.dim() == 0:\n",
        "            input_ = input_.view(1)\n",
        "            \n",
        "        # Add batch dimension if needed\n",
        "        if input_.dim() == 1:\n",
        "            input_ = input_.view(1, 1)        \n",
        "            embedd_output = self.embedding(input_)  \n",
        "        \n",
        "        # Pass the embedding through the GRU\n",
        "        gru_output, hidden = self.gru(embedd_output, hidden)  \n",
        "        \n",
        "        # Pass it to the output layer\n",
        "        output = self.output_layer(gru_output)  \n",
        "        \n",
        "        # Reshape for cross entropy\n",
        "        output = output.squeeze(0)\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return Variable(torch.zeros(self.num_layers, 1, self.hidden_size))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "aZWMbY1o8qLv",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "da793a49917dc4882e7e70f04d07a777",
          "grade": false,
          "grade_id": "cell-b9299fddeb082b4e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Creating the Training Examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "B-ngTV6Q8qLv",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f6eaeb80c370b32f26eda2ac1be57444",
          "grade": false,
          "grade_id": "cell-83bf9e1b0374206c",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Each chunk will be turned into a tensor by looping through the characters of the string and looking up the index of each character in `all_characters`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "98wyNtkw8qLv",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "cc87bca342db2fde1b3957f48bcfe857",
          "grade": false,
          "grade_id": "cell-5360afdd0b03b1f4",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "05623659-53d1-40b4-d75c-6432d5c23b90",
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([10, 11, 12, 39, 40, 41])\n"
          ]
        }
      ],
      "source": [
        "# Turn a string into list of longs\n",
        "def chars_to_tensor(string):\n",
        "    tensor = torch.zeros(len(string)).long()\n",
        "    for c in range(len(string)):\n",
        "        tensor[c] = all_characters.index(string[c])\n",
        "    return Variable(tensor)\n",
        "\n",
        "print(chars_to_tensor('abcDEF'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "cYh_R1K88qLv",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f7fab2aa0d22a697fcc3d675b1821875",
          "grade": false,
          "grade_id": "cell-6e7b3d9e8c9396bb",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Now we can assemble a pair of input and target tensors (i.e. a single training example) for training, from a random chunk. The input will be all characters *except the last*, and the target will be all characters *except the first*. So if our chunk is \"abc\" the input will correspond to \"ab\" while the target is \"bc\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "QFDYhW3a8qLv",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "adf90d7ec6728b2f45d1e8de5c47203c",
          "grade": false,
          "grade_id": "cell-d3539c5f1d96a188",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": [
        "def random_training_set():\n",
        "    chunk = random_chunk()\n",
        "    inp = chars_to_tensor(chunk[:-1])\n",
        "    target = chars_to_tensor(chunk[1:])\n",
        "    return inp, target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "eU6VTX8F8qLv",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "18a6bf800d9bc590739b15ba01dda408",
          "grade": false,
          "grade_id": "cell-16d13f3b273395ac",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Evaluating\n",
        "\n",
        "To evaluate the network we will feed one character at a time, use the outputs of the network as a probability distribution for the next character, and repeat. To start generation we pass a priming string to start building up the hidden state, from which we then generate one character at a time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "xeoACNc78qLv",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a47c721a818979b886f119401206e756",
          "grade": false,
          "grade_id": "cell-44ab27a8fee696ad",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def evaluate(prime_str='A', predict_len=100, temperature=0.8):\n",
        "    hidden = model.init_hidden()\n",
        "    prime_input = chars_to_tensor(prime_str)\n",
        "    predicted = prime_str\n",
        "\n",
        "    # Use priming string to \"build up\" hidden state\n",
        "    for p in range(len(prime_str) - 1):\n",
        "        _, hidden = model(prime_input[p], hidden)\n",
        "    inp = prime_input[-1]\n",
        "\n",
        "    for p in range(predict_len):\n",
        "        output, hidden = model(inp, hidden)\n",
        "\n",
        "        # Sample from the network as a multinomial distribution\n",
        "        output_dist =  F.softmax(output / temperature, dim=-1)\n",
        "        top_i = torch.multinomial(output_dist, 1)[0]\n",
        "\n",
        "        # Add predicted character to string and use as next input\n",
        "        predicted_char = all_characters[top_i]\n",
        "        predicted += predicted_char\n",
        "        inp = chars_to_tensor(predicted_char)\n",
        "\n",
        "    return predicted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "iNmsUvyM8qLv",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "3fffa10554299eaae14cc007fea3935a",
          "grade": false,
          "grade_id": "cell-1d3fd015fe8f64d1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "AiCVg5Ec8qLv",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "8a98218b35f47137eeba1ba1aead0700",
          "grade": false,
          "grade_id": "cell-a209b293a8850a57",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "The main training function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Wug0q2Me8qLv",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "eb3bfcd4d49b2f2672447d8c65b6cb05",
          "grade": false,
          "grade_id": "cell-e246cbd9689e1a6d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": [
        "def train(inp, target):\n",
        "    hidden = model.init_hidden()\n",
        "    model.zero_grad()\n",
        "    loss = 0\n",
        "\n",
        "    for c in range(chunk_len):\n",
        "        output, hidden = model(inp[c], hidden)\n",
        "        loss += criterion(output, target[c].view(-1))\n",
        "        \n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item() / chunk_len"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "hFBSiQqS8qLv",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "bfb863e279db4b170c35d8d0c7a37a1f",
          "grade": false,
          "grade_id": "cell-05ce9b9275e0d1cc",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "A helper to print the amount of time passed:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "vIzUAL-a8qLv",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "16d7b53f211a6a1bef71c1dd2d1271cf",
          "grade": false,
          "grade_id": "cell-cb78afef7022f9a1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": [
        "import time, math\n",
        "\n",
        "def time_since(since):\n",
        "    s = time.time() - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return f'{m}m {math.floor(s)}s'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "pAlXhasn8qLv",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2b368f1767ddd0eddca44249fa47ed32",
          "grade": true,
          "grade_id": "cell-98f46bec0b8c87cc",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# DO NOT DELETE THIS CELL\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "0Xva5o5I8qLv",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "98abd7dd7805753c2e7b635f1265cb73",
          "grade": false,
          "grade_id": "cell-baf25642209867dc",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Define the training parameters, instantiate the model, and start training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "pRLHP-UQ8qLw",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ab44452ad9f838e0b56e1fc154ab6125",
          "grade": false,
          "grade_id": "cell-4900f92ae503be69",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[time elapsed: 0m 7s  ;  epochs: 100 (5.0%)  ;  loss: 2.329]\n",
            "Whay: susith an er hat mear mand in sut suarod durst y, ues thath the quand che to thou an thy thou meant fot hat.\n",
            "\n",
            "UENI wall sthe sutther hill not seake myt, a's my kis ou he ard nepent sull\n",
            "His spuar, \n",
            "\n",
            "[time elapsed: 0m 14s  ;  epochs: 200 (10.0%)  ;  loss: 1.797]\n",
            "Whimerce an frorrtw.\n",
            "\n",
            "ICANG VI:\n",
            "What leeente berothere rese?\n",
            "Ight\n",
            "And wath Kay uagh igh what lane thy whour exet vingot thou sexasth ost of thad hagake,\n",
            "As the muth\n",
            "Yet san, I ar a cathere my Hands,\n",
            "My  \n",
            "\n",
            "[time elapsed: 0m 21s  ;  epochs: 300 (15.0%)  ;  loss: 2.108]\n",
            "Whirs, of a cash'ch:\n",
            "And the dot sherearlem, and leield thould, ensupoured now we uper ce thes as bore him, beeter the caught\n",
            "Let the wast\n",
            "Tim o munget the eaved Rower lordwam secotm not lord, me good,  \n",
            "\n",
            "[time elapsed: 0m 27s  ;  epochs: 400 (20.0%)  ;  loss: 2.007]\n",
            "Which of thet by hatinged.\n",
            "\n",
            "Pedo, and at too prise am his depuell day\n",
            "Him E'ling your now to reaveftiought and that the his menterly\n",
            "I'll in sto grase he come is a your sit you paid that thy liens unch, \n",
            "\n",
            "[time elapsed: 0m 34s  ;  epochs: 500 (25.0%)  ;  loss: 2.004]\n",
            "Whomble meion be me, the be to moded\n",
            "resed that upiatced in her, bee's are hing in hes with me do suppellwellost him do bity,\n",
            "Head conter sevef-gook worrsel,\n",
            "And you and I stay.\n",
            "\n",
            "JUOKE:\n",
            "Of no bet to thy \n",
            "\n",
            "[time elapsed: 0m 42s  ;  epochs: 600 (30.0%)  ;  loss: 1.8]\n",
            "Why here well with feallopent my wonglace of man?\n",
            "Will we Sones to to till with the willow and that that his sid\n",
            "To frine on were some them of to deant,\n",
            "And declannand were thee,\n",
            "I porest it she the dot \n",
            "\n",
            "[time elapsed: 0m 48s  ;  epochs: 700 (35.0%)  ;  loss: 1.696]\n",
            "What your pecought hath mone, to thou\n",
            "Wheher to be bear to days or it hamping there\n",
            "I were breack bectorries will\n",
            "To kencust God that have frow,\n",
            "Nold the that all the borce:\n",
            "Whie hir, brates siroun the  \n",
            "\n",
            "[time elapsed: 0m 55s  ;  epochs: 800 (40.0%)  ;  loss: 1.79]\n",
            "Whithing sword: what, am are and's latt restcent.\n",
            "\n",
            "LORTES:\n",
            "I loven mishers you wimpost of give like?\n",
            "\n",
            "SLoNZ:\n",
            "Here thou doth comeman,\n",
            "Stye son they wombo my kind sendful fort\n",
            "A hope you, were it what som \n",
            "\n",
            "[time elapsed: 1m 2s  ;  epochs: 900 (45.0%)  ;  loss: 1.728]\n",
            "Why, neevietter if,\n",
            "With you shall now you. I'll probether so.\n",
            "\n",
            "GLOUCESTER:\n",
            "I said reat, blast dray as to and you drake as sable very of his modefore of I am for\n",
            "Alich: but alrear I of let with the but  \n",
            "\n",
            "[time elapsed: 1m 9s  ;  epochs: 1000 (50.0%)  ;  loss: 1.718]\n",
            "When. Gow you, ale-with to menic muck and see that your have dine,\n",
            "And the makest there he nowt asmebsio,\n",
            "The spead midds\n",
            "My lad pread noses, at be leaves,\n",
            "And intenve sholl best not treat him, good her \n",
            "\n",
            "[time elapsed: 1m 16s  ;  epochs: 1100 (55.00000000000001%)  ;  loss: 1.84]\n",
            "Whe am our to\n",
            "quit may our had Brecon the hameless\n",
            "Thee pright; stank, and of a with pritio.\n",
            "\n",
            "LEONTES:\n",
            "O sthere hour be fim, and know the man stold,\n",
            "With husself I me sace a fathing manopt digh protas!\n",
            " \n",
            "\n",
            "[time elapsed: 1m 23s  ;  epochs: 1200 (60.0%)  ;  loss: 1.582]\n",
            "Which have bey too suls,\n",
            "And so with sied chirctors bade\n",
            "the have you man my fring fold my more the defing,\n",
            "And tround you ight it so to deance it my live perity too or plott,\n",
            "And love to the coutine or \n",
            "\n",
            "[time elapsed: 1m 30s  ;  epochs: 1300 (65.0%)  ;  loss: 1.717]\n",
            "When way?\n",
            "\n",
            "KING RICHANURY:\n",
            "Sear an the brispiest:\n",
            "Lets, great thim, hast of him fallosselty.\n",
            "She shall there of leaster eed hithore and betare it.\n",
            "\n",
            "KING RICHARD III:\n",
            "The leams:\n",
            "O done our wash my mish.\n",
            " \n",
            "\n",
            "[time elapsed: 1m 37s  ;  epochs: 1400 (70.0%)  ;  loss: 1.685]\n",
            "Whight pased all me what siun.\n",
            "\n",
            "LADY ANNCE:\n",
            "If you dand in a bothy; if nersed he counds: betoldy,\n",
            "Here worth thing the for we dear are beganst his isor,\n",
            "Here with there canse, so hast sheed that that Ma \n",
            "\n",
            "[time elapsed: 1m 44s  ;  epochs: 1500 (75.0%)  ;  loss: 1.693]\n",
            "What eap gentlest let not,\n",
            "And and sother will I Lond prain! the see\n",
            "carber full to are that somere farm me panous who cannot clones.\n",
            "\n",
            "DUCKIFF:\n",
            "Fear his of thouse me vileve of suntle,\n",
            "And his mut murnic \n",
            "\n",
            "[time elapsed: 1m 51s  ;  epochs: 1600 (80.0%)  ;  loss: 1.646]\n",
            "Which to leaving\n",
            "To worldius not in my dilles it offence,\n",
            "Is and him man: let the will; shall gare?\n",
            "\n",
            "PAULET:\n",
            "And that stom haghter's seen my become my not.\n",
            "\n",
            "Lieflf;\n",
            "And you, a ming im, with, for the fai \n",
            "\n",
            "[time elapsed: 1m 57s  ;  epochs: 1700 (85.0%)  ;  loss: 1.646]\n",
            "Wh the mothere be work the maging\n",
            "Swead of may amioind most is descure?\n",
            "\n",
            "VIO:\n",
            "Vose may to parted feed in my mould thus, should can in must'd on the dead.\n",
            "\n",
            "SICFIO:\n",
            "All the ill sevies: so the must it do d \n",
            "\n",
            "[time elapsed: 2m 4s  ;  epochs: 1800 (90.0%)  ;  loss: 1.638]\n",
            "Whander:\n",
            "That loss that sear\n",
            "And peach throu by Speret will feereath all looks with all is prece,\n",
            "Tere make the kinst though thee but bod,\n",
            "With all a blood and lossess heart of facked and mages\n",
            "wher'd b \n",
            "\n",
            "[time elapsed: 2m 11s  ;  epochs: 1900 (95.0%)  ;  loss: 1.866]\n",
            "Which that this know me refly.\n",
            "\n",
            "PAOUCESTER:\n",
            "\n",
            "CORIOLANUS:\n",
            "Come, budds, Nortes, you and with like that teach the sperbul of tencing not thee,\n",
            "That his house could comm in conto were the bogy his\n",
            "at to con \n",
            "\n",
            "[time elapsed: 2m 18s  ;  epochs: 2000 (100.0%)  ;  loss: 1.967]\n",
            "Whand-fools sowneds you and\n",
            "grace, as you look precedio! we dain, loess, sheshaly that give aye,\n",
            "Sent to the speak of you batt victesmer more one is well\n",
            "Here that will grace, this sir, for the punce, t \n",
            "\n"
          ]
        }
      ],
      "source": [
        "n_epochs = 2000\n",
        "print_every = 100\n",
        "plot_every = 10\n",
        "hidden_size = 100  # (D_h from the handout)\n",
        "num_layers = 1\n",
        "lr = 0.005\n",
        "\n",
        "model = OurModel(n_characters, hidden_size, n_characters, num_layers)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "start = time.time()\n",
        "all_losses = []\n",
        "loss_avg = 0\n",
        "\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    loss = train(*random_training_set())\n",
        "    loss_avg += loss\n",
        "\n",
        "    if epoch % print_every == 0:\n",
        "        print(f'[time elapsed: {time_since(start)}  ;  epochs: {epoch} ({epoch / n_epochs * 100}%)  ;  loss: {loss:.4}]')\n",
        "        print(evaluate('Wh', 200), '\\n')  # generate text starting with 'Wh'\n",
        "\n",
        "    if epoch % plot_every == 0:\n",
        "        all_losses.append(loss_avg / plot_every)\n",
        "        loss_avg = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "dXeVkk298qLw",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "8584d3be75d90a5197e7133411e0021d",
          "grade": false,
          "grade_id": "cell-ff9d72dafefa0a23",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Training Loss\n",
        "\n",
        "Plotting the the losses that were computed during training can provide a further indication that the network was indeed learning (Add your plot to the final submission pdf)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "S2SZanbV8qLw",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "357a8a13a77f5e3b3e336e022dc596d4",
          "grade": false,
          "grade_id": "cell-f91bb597844b8f7d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x2b220d670>]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.grid(True)\n",
        "plt.xlabel('# of epochs (divided by plot_every)')\n",
        "plt.ylabel('average loss')\n",
        "plt.plot(all_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model 2 Shakespeare Perplexity: 7.28521500058544\n",
            "Model 2 Wikipedia Perplexity: 20.361703563059347\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def preplexity(eval_data_path, temperature=0.8):\n",
        "    \"\"\"\n",
        "    Evaluate perplexity\n",
        "    \"\"\"\n",
        "    with open(eval_data_path, \"r\", encoding=\"utf-8\") as f:\n",
        "      data = unidecode.unidecode(f.read())\n",
        "    hidden = model.init_hidden()\n",
        "    perplexity = 0\n",
        "    for i in range(len(data) - 1):\n",
        "      output, hidden = model(chars_to_tensor(data[i]), hidden)\n",
        "      output_prob =  F.softmax(output / temperature, dim=-1) # Converts raw logits into probabilities over the character vocabulary\n",
        "      ind = all_characters.index(data[i + 1]) # Retrieves the index of the true next character \n",
        "      next_character_prob = output_prob[0][ind] # Extracts the probability of the true next character \n",
        "      prob = next_character_prob.item()\n",
        "      perplexity += np.log2(prob)\n",
        "    perplexity = 2 ** (- perplexity / len(data))\n",
        "    return perplexity\n",
        "\n",
        "print(\"Model 2 Shakespeare Perplexity: \" + str(preplexity(\"HW2/shakespeare_for_perplexity.txt\")))\n",
        "print(\"Model 2 Wikipedia Perplexity: \" + str(preplexity(\"HW2/wikipedia_for_perplexity.txt\")))"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
